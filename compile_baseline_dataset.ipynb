{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f6cd836-bdf7-430b-8ae0-00e0faf6b09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import re\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "import support.ts_class as ts_class\n",
    "import support.load_and_process_data as lpdata\n",
    "import math\n",
    "import gspread\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfd01088-a0df-4a33-8695-475cf8a80226",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "ts_class = reload(ts_class)\n",
    "lpdata = reload(lpdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d4095be-2874-4941-8209-91959fffd2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/11/04 15:53:30 WARN Utils: Your hostname, Esas-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.10.171 instead (on interface en0)\n",
      "22/11/04 15:53:30 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/anaconda3/envs/traiding_spark_delta/lib/python3.9/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/anaconda3/envs/traiding_spark_delta/lib/python3.9/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/esak/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/esak/.ivy2/jars\n",
      "io.delta#delta-core_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-2ca87255-daab-4ebe-8386-d6d91b1e8c75;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-core_2.12;1.2.1 in central\n",
      "\tfound io.delta#delta-storage;1.2.1 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.8 in central\n",
      "\tfound org.codehaus.jackson#jackson-core-asl;1.9.13 in central\n",
      ":: resolution report :: resolve 246ms :: artifacts dl 9ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-core_2.12;1.2.1 from central in [default]\n",
      "\tio.delta#delta-storage;1.2.1 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.8 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-core-asl;1.9.13 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   4   |   0   |   0   |   0   ||   4   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-2ca87255-daab-4ebe-8386-d6d91b1e8c75\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 4 already retrieved (0kB/6ms)\n",
      "22/11/04 15:53:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from delta import *\n",
    "\n",
    "builder = pyspark.sql.SparkSession.builder.appName(\"MyApp\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2231164c-977d-496c-8447-f5e5620942b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'delta'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdelta\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtables\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'delta'"
     ]
    }
   ],
   "source": [
    "from delta.tables import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "import pyspark.pandas as ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2867d1e-366c-4208-b511-af8b19d2a880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57a3010a-4719-4c41-a5c3-62d4b87c2c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/11/04 17:50:09 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 300787 ms exceeds timeout 120000 ms\n",
      "22/11/04 17:50:09 WARN SparkContext: Killing executors is not supported by current scheduler.\n"
     ]
    }
   ],
   "source": [
    "table = \"/Users/esak/Projects/stock_traiding/forecast_indices/datasets/stocks_per_minute\"\n",
    "ec_table = \"/Users/esak/Projects/stock_traiding/forecast_indices/datasets/economic_data\"\n",
    "table_path = \"/Users/esak/Projects/stock_traiding/forecast_indices/datasets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c528bee-691e-4769-86a3-c65d307d5519",
   "metadata": {},
   "outputs": [],
   "source": [
    "msft_2y_trailing = lpdata.av_get_intraday('MSFT',\"1min\",2,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e638d71f-5188-4088-a64b-70933f2442b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "msft_2y_trailing.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced1b0b0-5e1a-490c-b579-e3dc6bf5a54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "msft_2y_trailing = msft_2y_trailing.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66003bb-44a2-4f16-b26e-d93148047e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "msft_2y_trailing.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebcfe34-b7bc-4b1c-88f8-022ec8a44b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(msft_2y_trailing[\"Close\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3863b20d-4b9a-4d83-a9a6-06d35b3ba4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "TODAY = datetime.today().strftime('%Y-%m-%d')\n",
    "START_DATE = '1991-01-01 00:00:00'\n",
    "#START_DATE = '2019-01-01 00:00:00'\n",
    "END_DATE = TODAY+' 23:59:59'\n",
    "PERIOD = START_DATE[0:4]+\"-\"+END_DATE[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959eb400-ca36-424c-b03f-50fe0c8015fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('raw_datasets.txt', 'r') as fd:\n",
    "    reader = csv.reader(fd)\n",
    "    for row in reader:\n",
    "        files = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "512c6eb2-956e-4117-bd74-6420abf2fd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['SP500','30Y_BOND','10Y_NOTE','GOLD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44d4f056-45a2-48be-9365-26f329ac515b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/10/27 15:15:56 WARN MemoryManager: Total allocation exceeds 95,00% (1 020 054 720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n",
      "22/10/27 15:16:07 WARN MemoryManager: Total allocation exceeds 95,00% (1 020 054 720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n",
      "22/10/27 16:12:44 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 287864 ms exceeds timeout 120000 ms\n",
      "22/10/27 16:12:45 WARN SparkContext: Killing executors is not supported by current scheduler.\n"
     ]
    }
   ],
   "source": [
    "for index, file in enumerate(files):\n",
    "    schema = (StructType()\n",
    "              .add(\"Date\",StringType(),True)\n",
    "              .add(\"Time\",StringType(),True)\n",
    "              .add(\"Open\",DoubleType(),True)\n",
    "              .add(\"High\",DoubleType(),True)\n",
    "              .add(\"Low\",DoubleType(),True)\n",
    "              .add(\"Close\",DoubleType(),True)\n",
    "              .add(\"Volume\",LongType(),True)\n",
    "             )\n",
    "    df = (spark.read.format(\"csv\")\n",
    "                  .option(\"header\", False)\n",
    "                  .option(\"delimiter\",\";\")\n",
    "                  .schema(schema)\n",
    "                  .load(file)\n",
    "                 )\n",
    "    df = (df\n",
    "      .withColumn(\"Datetime\", to_timestamp(concat_ws(' ' ,col(\"Date\"),substring(col(\"Time\"), 0, 5)),'dd/MM/yyyy HH:mm'))\n",
    "      .drop(col(\"Date\"))\n",
    "      .drop(col(\"Time\"))\n",
    "      .withColumn(\"Ticker\",lit(tickers[index]))\n",
    "     )\n",
    "    df.write.format(\"delta\").mode(\"overwrite\").save(table_path+tickers[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e1e276-a962-449b-b7b5-52d22492b86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516cad34-6bd6-466d-8e73-c11e5c0375a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08680b8e-8eb7-43b4-a3ad-c6ea45671c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.format(\"delta\").mode(\"overwrite\").save(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1a6fc7-5015-41dd-82e1-196b1d18602a",
   "metadata": {},
   "outputs": [],
   "source": [
    "msft_2y_trailing.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faffac9a-a944-4b8c-a2ec-872970829285",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_datetime = msft_2y_trailing.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2991e83-a583-4fe5-b480-13c4db4fd098",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(cut_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3f0d1f-b850-4899-a75b-6ab9c1c33111",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaTable = DeltaTable.forPath(spark, table)\n",
    "\n",
    "# Declare the predicate by using Spark SQL functions.\n",
    "deltaTable.delete(col('Datetime') >= str(cut_datetime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d45cce-d883-4449-b3f1-bc7f325fbce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "msft_trailing_spark = ps.from_pandas(msft_2y_trailing).to_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a2f8de-0cec-4b18-a5c5-5a5e436500aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "msft_trailing_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc727d2-7e71-409d-b2b8-06bf9653af12",
   "metadata": {},
   "outputs": [],
   "source": [
    "msft_trailing_spark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2fa5a2-e48d-40d0-9235-246e8a150f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "msft_trailing_spark.write.format(\"delta\").mode(\"append\").save(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b129c700-aaf8-437c-82ea-ac98b88c35d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * \\\n",
    "FROM delta.`{}` \\\n",
    "ORDER BY Datetime DESC\"\\\n",
    ".format(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "539b4dc9-e590-46ab-a186-8bf77b397ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:=============================================>            (7 + 2) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+------+------+-------------------+------+\n",
      "|  Open|  High|   Low| Close|Volume|           Datetime|Ticker|\n",
      "+------+------+------+------+------+-------------------+------+\n",
      "| 242.3| 242.3| 242.3| 242.3|  1669|2022-10-21 19:59:00|  MSFT|\n",
      "|242.22|242.22|242.22|242.22|   186|2022-10-21 19:57:00|  MSFT|\n",
      "| 242.3| 242.3| 242.3| 242.3|   278|2022-10-21 19:56:00|  MSFT|\n",
      "|242.41|242.41| 242.4|242.41|  1352|2022-10-21 19:49:00|  MSFT|\n",
      "|242.41|242.41|242.41|242.41|   307|2022-10-21 19:48:00|  MSFT|\n",
      "|242.42|242.42|242.42|242.42|   161|2022-10-21 19:44:00|  MSFT|\n",
      "| 242.4| 242.4| 242.4| 242.4|   252|2022-10-21 19:43:00|  MSFT|\n",
      "|242.47|242.47|242.47|242.47|   126|2022-10-21 19:41:00|  MSFT|\n",
      "| 242.3| 242.3| 242.3| 242.3|   394|2022-10-21 19:38:00|  MSFT|\n",
      "|242.32|242.32|242.32|242.32|   194|2022-10-21 19:36:00|  MSFT|\n",
      "| 242.3| 242.3| 242.3| 242.3|   231|2022-10-21 19:34:00|  MSFT|\n",
      "|242.34|242.34| 242.3| 242.3|   585|2022-10-21 19:22:00|  MSFT|\n",
      "|242.47|242.47|242.47|242.47|   128|2022-10-21 19:16:00|  MSFT|\n",
      "|242.45|242.45|242.45|242.45|   250|2022-10-21 19:10:00|  MSFT|\n",
      "|242.36|242.36|242.35|242.35|  4159|2022-10-21 19:09:00|  MSFT|\n",
      "|242.48|242.48|242.48|242.48|   209|2022-10-21 19:00:00|  MSFT|\n",
      "|242.32|242.32|242.32|242.32|   275|2022-10-21 18:59:00|  MSFT|\n",
      "| 242.5| 242.5| 242.5| 242.5|   603|2022-10-21 18:58:00|  MSFT|\n",
      "|242.35|242.35|242.35|242.35|   151|2022-10-21 18:50:00|  MSFT|\n",
      "|242.21|242.21|242.21|242.21|   369|2022-10-21 18:48:00|  MSFT|\n",
      "+------+------+------+------+------+-------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580a1dfa-cba0-4aeb-acee-4701d838370d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"delta\").load(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cf4a80-b105-47af-a9f0-8e8f7508660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "msft_close_np = (np.array(df\n",
    "                          .filter(col(\"Datetime\") > \"2015-01-01\")\n",
    "                          .sort(col(\"Datetime\"))\n",
    "                          .select(col(\"Close\"))\n",
    "                          .collect())\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356421ed-6f4f-47c5-9df2-6e72b7dd0ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(msft_close_np)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca395c8-b04d-4758-910d-2d7c7e5c87b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort(col(\"Datetime\")).withColumn(\"Year\", year(\"Datetime\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d547bf4e-34f5-4df6-a7a1-d48f04347cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe86f62-6355-482c-8ccc-8cc5332ff411",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.option(\"header\", True).option(\"timestampFormat\", \"yyyy-MM-dd HH:mm:ss\").partitionBy(\"Year\").mode(\"overwrite\").csv('data/msft_full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d071dab9-0d5a-44d7-beb9-e395fe9dead5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc = gspread.service_account(filename='/Users/esak/.config/gspread/service_account.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6ca1b80d-b943-4825-8154-8a8fefbe8123",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving economic data...\n"
     ]
    }
   ],
   "source": [
    "ec_data = lpdata.retrieve_data([\"ec_data_1980_2000\",\"ec_2001_2009\",\"ec_2010_2014\",\"ec_2015_2019\",\"ec_2020\",\"ec_2021\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c159b233-9984-4301-9103-559b760522b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66268, 5)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ec_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6681f266-68a5-4e16-808d-f8ed089f24ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To correct timezone\n",
    "ec_data[\"Datetime\"] = ec_data[\"Datetime\"] + timedelta(hours=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8a0a46b0-b3e0-4943-927b-10f47f794c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Event</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Forecast</th>\n",
       "      <th>Previous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980-01-01 05:00:00</td>\n",
       "      <td>All Car Sales</td>\n",
       "      <td>1.035000e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9720000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980-01-01 05:00:00</td>\n",
       "      <td>All Truck Sales</td>\n",
       "      <td>2.840000e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2940000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1980-01-01 05:00:00</td>\n",
       "      <td>Capacity Utilization Rate</td>\n",
       "      <td>8.410000e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1980-01-01 05:00:00</td>\n",
       "      <td>CB Consumer Confidence</td>\n",
       "      <td>9.070000e+01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1980-01-01 05:00:00</td>\n",
       "      <td>CB Employment Trends Index</td>\n",
       "      <td>6.620000e+01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Datetime                       Event        Actual  Forecast  \\\n",
       "0 1980-01-01 05:00:00               All Car Sales  1.035000e+07       NaN   \n",
       "1 1980-01-01 05:00:00             All Truck Sales  2.840000e+06       NaN   \n",
       "2 1980-01-01 05:00:00   Capacity Utilization Rate  8.410000e-01       NaN   \n",
       "3 1980-01-01 05:00:00      CB Consumer Confidence  9.070000e+01       NaN   \n",
       "4 1980-01-01 05:00:00  CB Employment Trends Index  6.620000e+01       NaN   \n",
       "\n",
       "      Previous  \n",
       "0  9720000.000  \n",
       "1  2940000.000  \n",
       "2        0.842  \n",
       "3       90.200  \n",
       "4       66.500  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ec_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0ada45d4-b951-431d-a742-1c20ec266453",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/10/26 20:50:27 WARN MemoryManager: Total allocation exceeds 95,00% (1 020 054 720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "ps.from_pandas(ec_data).to_spark().write.format(\"delta\").mode(\"overwrite\").save(ec_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
